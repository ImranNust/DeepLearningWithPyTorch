{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOGmusXFBZA/FO3nntKXe2y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ImranNust/DeepLearningWithPyTorch/blob/main/Chapter4/Module3_RepresentingTabularData.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1> <center> <b> <u> Introduction </u> </b> </center> </h1>\n",
        "\n",
        "\n",
        "\n",
        "* The simplest form of data we’ll encounter on a machine learning job is sitting in a spreadsheet, CSV file, or database. Whatever the medium, it’s a table containing one row per sample (or record), where columns contain one piece of information about our sample.\n",
        "\n",
        "* Columns may contain numerical values, like temperatures at specific locations; or labels, like a string expressing an attribute of the sample, like “blue.” Therefore, tabular data is typically not homogeneous: different columns don’t have the same type. We might have a column showing the weight of apples and another encoding their color in a label.\n",
        "\n",
        "* PyTorch tensors, on the other hand, are homogeneous. Information in PyTorch is\n",
        "typically encoded as a number, typically floating-point (though integer types and Boolean are supported as well). This numeric encoding is deliberate, since neural networks are mathematical entities that take real numbers as inputs and produce real numbers as output through successive application of matrix multiplications and nonlinear functions.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "V5dgPwJrM661"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2> <center> <b> <u> Using a real-world dataset </u> </b> </center> </h2>\n",
        "\n",
        "* Our first job as deep learning practitioners is to encode heterogeneous, real-world data into a tensor of floating-point numbers, ready for consumption by a neural network.\n",
        "\n",
        "* The `tabular-wine` file contains a comma-separated collection of values organized in 12 columns preceded by a header line containing the column names. The first 11 columns contain values of chemical variables, and the last column contains the sensory quality score from 0 (very bad) to 10 (excellent). These are the column names in the order they appear in the dataset:\n",
        "    - fixed acidity\n",
        "    - volatile acidity\n",
        "    - citric acid\n",
        "    - residual sugar\n",
        "    - chlorides\n",
        "    - free sulfur dioxide\n",
        "    - total sulfur dioxide\n",
        "    - density\n",
        "    - pH\n",
        "    - sulphates\n",
        "    - alcohol\n",
        "    - quality\n",
        "\n",
        "![](https://raw.githubusercontent.com/ImranNust/DeepLearningWithPyTorch/main/Images/winedataset.png)\n",
        "\n",
        "* A possible machine learning task on this dataset is predicting the quality score from chemical characterization alone.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "kb2bg5eIN4Ff"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2> <center> <b> <u> Loading a wine data tensor </u> </b> </center> </h2>\n",
        "\n",
        "* Let’s see how we can load the data using Python and then turn it into a PyTorch tensor. Python offers several options for quickly loading a CSV file. Three popular options are\n",
        "    - The csv module that ships with Python\n",
        "    - NumPy\n",
        "    - Pandas (This option is the most convenient and perferable, but as we are\n",
        "      already familiar with numpy and pytorch, so we will stick to that)\n",
        "\n"
      ],
      "metadata": {
        "id": "8NzXxAcJDsHP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "try:\n",
        "  wine_path = '/content/winequality-white.csv'\n",
        "  wineq_numpy = np.loadtxt(wine_path, dtype = np.float32, delimiter = ';',\n",
        "                          skiprows = 1)\n",
        "except:\n",
        "  !git clone https://github.com/ImranNust/DeepLearningWithPyTorch\n",
        "  !mv DeepLearningWithPyTorch/Images/winequality-white.csv /content/\n",
        "  !rm -rf DeepLearningWithPyTorch\n",
        "  wine_path = '/content/winequality-white.csv'\n",
        "  wineq_numpy = np.loadtxt(wine_path, dtype = np.float32, delimiter = ';',\n",
        "                           skiprows = 1)\n",
        "  \n",
        "print(wineq_numpy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmnrw7-4Hpm2",
        "outputId": "f0afdb93-d360-4ce5-efa3-f8af60178296"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DeepLearningWithPyTorch'...\n",
            "remote: Enumerating objects: 202, done.\u001b[K\n",
            "remote: Counting objects: 100% (73/73), done.\u001b[K\n",
            "remote: Compressing objects: 100% (68/68), done.\u001b[K\n",
            "remote: Total 202 (delta 6), reused 59 (delta 3), pack-reused 129\u001b[K\n",
            "Receiving objects: 100% (202/202), 37.87 MiB | 21.83 MiB/s, done.\n",
            "Resolving deltas: 100% (16/16), done.\n",
            "[[ 7.    0.27  0.36 ...  0.45  8.8   6.  ]\n",
            " [ 6.3   0.3   0.34 ...  0.49  9.5   6.  ]\n",
            " [ 8.1   0.28  0.4  ...  0.44 10.1   6.  ]\n",
            " ...\n",
            " [ 6.5   0.24  0.19 ...  0.46  9.4   6.  ]\n",
            " [ 5.5   0.29  0.3  ...  0.38 12.8   7.  ]\n",
            " [ 6.    0.21  0.38 ...  0.32 11.8   6.  ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Here we just prescribe what the type of the 2D array should be (32-bit floating-point), the delimiter used to separate values in each row, and the fact that the first line should not be read since it contains the column names. \n",
        "\n",
        "Let’s check that all the data has been read and proceed to convert the NumPy array to a PyTorch tensor:\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "bXh8oh4twZkY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv, torch\n",
        "col_list = next(csv.reader(open(wine_path), delimiter = ';'))\n",
        "print('The downloaded file has shape: {}\\n and column names: {}'.\n",
        "      format(wineq_numpy.shape, col_list))\n",
        "\n",
        "wineq = torch.from_numpy(wineq_numpy)\n",
        "\n",
        "print(wineq.shape, wineq.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amaOAph87yZf",
        "outputId": "f56bf8bf-e957-4811-d5d1-878a9e4565ab"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The downloaded file has shape: (4898, 12)\n",
            " and column names: ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol', 'quality']\n",
            "torch.Size([4898, 12]) torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "At this point, we have a floating-point torch.Tensor containing all the columns,\n",
        "including the last, which refers to the quality score.\n",
        "\n",
        "**[IMPORTANT]** Please read about three types of data: Continuous, ordinal, and categorical values\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "umRQ9ZxqLz6s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2> <center> <b> <u> Representing Scores </u> </b> </center> </h2>\n",
        "\n",
        "We could treat the score as a continuous variable, keep it as a real number, and perform a regression task, or treat it as a label and try to guess the label from the chemical analysis in a classification task. In both approaches, we will typically remove the score from the tensor of input data and keep it in a separate tensor, so that we can use the score as the ground truth without it being input to our model:"
      ],
      "metadata": {
        "id": "Ne5zQj06MQ8x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = wineq[:, :-1]\n",
        "print(data, data.shape)\n",
        "\n",
        "target = wineq[:, -1]\n",
        "print(target, target.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olPNXh10MKCR",
        "outputId": "6e4c80b7-93fc-4e9e-be89-698aa6cdfc9a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 7.0000,  0.2700,  0.3600,  ...,  3.0000,  0.4500,  8.8000],\n",
            "        [ 6.3000,  0.3000,  0.3400,  ...,  3.3000,  0.4900,  9.5000],\n",
            "        [ 8.1000,  0.2800,  0.4000,  ...,  3.2600,  0.4400, 10.1000],\n",
            "        ...,\n",
            "        [ 6.5000,  0.2400,  0.1900,  ...,  2.9900,  0.4600,  9.4000],\n",
            "        [ 5.5000,  0.2900,  0.3000,  ...,  3.3400,  0.3800, 12.8000],\n",
            "        [ 6.0000,  0.2100,  0.3800,  ...,  3.2600,  0.3200, 11.8000]]) torch.Size([4898, 11])\n",
            "tensor([6., 6., 6.,  ..., 6., 7., 6.]) torch.Size([4898])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "If we want to transform the target tensor in a tensor of labels, we have two options, depending on the strategy or what we use the categorical data for. \n",
        "\n",
        "1. One is simply to treat labels as an integer vector of scores:\n",
        "```\n",
        "target = wineq[:, -1].long()\n",
        "target\n",
        "```\n",
        "If targets were string labels, like wine color, assigning an integer number to each string would let us follow the same approach.\n",
        "2. The other approach is one-hot encoding"
      ],
      "metadata": {
        "id": "c0WzL9uKNkc9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target = wineq[:, -1].long()\n",
        "target"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbrO4vyQMJ_V",
        "outputId": "dfdab475-0fd1-4c39-d672-41149508d95a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([6, 6, 6,  ..., 6, 7, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "<h2> <center> <b> <u> One-hot Encoding </u> </b> </center> </h2>\n",
        "\n",
        "The other approach is to build a one-hot encoding of the scores: that is, encode each of the 10 scores in a vector of 10 elements, with all elements set to 0 but one, at a different index for each score. This way, a score of 1 could be mapped onto the vector (1,0,0,0,0,0,0,0,0,0), a score of 5 onto (0,0,0,0,1,0,0,0,0,0), and so on. \n",
        "\n",
        "We can achieve one-hot encoding using the `scatter_` method, which fills the tensor with values from a source tensor along the indices provided as arguments:"
      ],
      "metadata": {
        "id": "KQ_Y1O6AOXyK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target_onehot = torch.zeros(target.shape[0], 10)\n",
        "target_onehot.scatter_(1, target.unsqueeze(1), 1.0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1QYyFFwLDwX",
        "outputId": "f220625c-da9e-4b2e-ba69-513909541c1e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "The arguments for `scatter_` are as follows:\n",
        "- The dimension along which the following two arguments are specified\n",
        "- A column tensor indicating the indices of the elements to scatter\n",
        "- A tensor containing the elements to scatter or a single scalar to scatter (1, in this case)\n",
        "\n",
        "\n",
        "PyTorch allows us to use class indices directly as targets while training neural networks. However, if we wanted to use the score as a categorical input to the network, we would have to transform it to a one-hot-encoded tensor.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "roDqSqnwQHhZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "<h2> <center> <b> <u> When To Categorize </u> </b> </center> </h2>\n",
        "\n",
        "How to treat columns with continuous, ordinal, and categorical data is summarized in the following figure.\n",
        "\n",
        "![](https://raw.githubusercontent.com/ImranNust/DeepLearningWithPyTorch/main/Images/whentocategorize.png)\n",
        "\n",
        "Our data tensor, containing the 11 variables associated with the chemical\n",
        "analysis. We can use the functions in the PyTorch Tensor API to manipulate our data in tensor form. \n",
        "\n",
        "Let’s first obtain the mean and standard deviations for each column:"
      ],
      "metadata": {
        "id": "tbt7Df84ZkXl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_mean = torch.mean(data, dim = 0)\n",
        "data_var = torch.var(data, dim = 0)\n",
        "\n",
        "print('Mean = \\n{} \\nVariance = \\n{}'.format(data_mean, data_var))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHDMOUBocD9n",
        "outputId": "0e3703a5-614c-4dd9-80b6-b58e257a1623"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean = \n",
            "tensor([6.8548e+00, 2.7824e-01, 3.3419e-01, 6.3914e+00, 4.5772e-02, 3.5308e+01,\n",
            "        1.3836e+02, 9.9403e-01, 3.1883e+00, 4.8985e-01, 1.0514e+01]) \n",
            "Variance = \n",
            "tensor([7.1211e-01, 1.0160e-02, 1.4646e-02, 2.5726e+01, 4.7733e-04, 2.8924e+02,\n",
            "        1.8061e+03, 8.9455e-06, 2.2801e-02, 1.3025e-02, 1.5144e+00])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "In this case, `dim=0` indicates that the reduction is performed along dimension `0`. At this point, we can normalize the data by subtracting the `mean` and dividing by the `standard deviation`, which helps with the learning process"
      ],
      "metadata": {
        "id": "QZ1Zl2_RcDX3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_normalized = (data - data_mean)/ torch.sqrt(data_var)\n",
        "print(data_normalized)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NprKogUJLKVo",
        "outputId": "237158d6-c609-4a9d-dac4-185bd5211aa6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.7208e-01, -8.1761e-02,  2.1326e-01,  ..., -1.2468e+00,\n",
            "         -3.4915e-01, -1.3930e+00],\n",
            "        [-6.5743e-01,  2.1587e-01,  4.7996e-02,  ...,  7.3995e-01,\n",
            "          1.3422e-03, -8.2419e-01],\n",
            "        [ 1.4756e+00,  1.7450e-02,  5.4378e-01,  ...,  4.7505e-01,\n",
            "         -4.3677e-01, -3.3663e-01],\n",
            "        ...,\n",
            "        [-4.2043e-01, -3.7940e-01, -1.1915e+00,  ..., -1.3130e+00,\n",
            "         -2.6153e-01, -9.0545e-01],\n",
            "        [-1.6054e+00,  1.1666e-01, -2.8253e-01,  ...,  1.0049e+00,\n",
            "         -9.6251e-01,  1.8574e+00],\n",
            "        [-1.0129e+00, -6.7703e-01,  3.7852e-01,  ...,  4.7505e-01,\n",
            "         -1.4882e+00,  1.0448e+00]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "<h2> <center> <b> <u> Finding Thresholds </u> </b> </center> </h2>\n",
        "\n",
        "Next, let’s start to look at the data with an eye to seeing if there is an easy way to tell good and bad wines apart at a glance. \n",
        "\n",
        "First, we’re going to determine which rows in gtarget correspond to a score less than or equal to 3:"
      ],
      "metadata": {
        "id": "xAsG39K7dGj1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bad_indexes = target <= 3\n",
        "print(bad_indexes.shape, bad_indexes.dtype, bad_indexes.sum())"
      ],
      "metadata": {
        "id": "GL5m4VrxPqFs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee879e78-ec41-4470-b5ab-c9a65ff3fee5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4898]) torch.bool tensor(20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Note that only 20 of the `bad_indexes` entries are set to `True`! By using a feature in PyTorch called `advanced indexing`, we can use a tensor with data type `torch.bool` to index the data tensor. This will essentially filter data to be only items (or rows) corresponding to `True` in the indexing tensor. The `bad_indexes` tensor has the same shape as `target`, with values of `False` or `True` depending on the outcome of the comparison between our threshold and each element in the original `target` tensor:\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "Gecw8Et0eQnJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bad_data = data[bad_indexes]\n",
        "bad_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KaTOJaIjeExu",
        "outputId": "9b451313-d551-4fd2-e6e4-8e7013114f31"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([20, 11])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that the new `bad_data` tensor has 20 rows, the same as the number of rows with `True` in the `bad_indexes` tensor. It retains all 11 columns. Now we can start to get information about wines grouped into good, middling, and bad categories. \n",
        "\n",
        "Let’s take the `.mean()` of each column:"
      ],
      "metadata": {
        "id": "sP1Vvgw9fLdx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bad_data = data[target<=3]\n",
        "mid_data = data[(target >= 3) & (target < 7)]\n",
        "good_data = data[target >= 7]\n",
        "\n",
        "bad_mean = torch.mean(bad_data, dim=0)\n",
        "mid_mean = torch.mean(mid_data, dim=0)\n",
        "good_mean = torch.mean(good_data, dim=0)\n",
        "\n",
        "for i, args in enumerate(zip(col_list, bad_mean, mid_mean, good_mean)):\n",
        "  print('{:2} {:20} {:6.2f} {:6.2f} {:6.2f}'.format(i, *args))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Ua8gwY-fBbk",
        "outputId": "5d6003fe-7fdc-49d6-f26a-1cfb63a806aa"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 0 fixed acidity          7.60   6.89   6.73\n",
            " 1 volatile acidity       0.33   0.28   0.27\n",
            " 2 citric acid            0.34   0.34   0.33\n",
            " 3 residual sugar         6.39   6.70   5.26\n",
            " 4 chlorides              0.05   0.05   0.04\n",
            " 5 free sulfur dioxide   53.33  35.52  34.55\n",
            " 6 total sulfur dioxide 170.60 141.98 125.25\n",
            " 7 density                0.99   0.99   0.99\n",
            " 8 pH                     3.19   3.18   3.22\n",
            " 9 sulphates              0.47   0.49   0.50\n",
            "10 alcohol               10.34  10.27  11.42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It looks like we’re on to something here: at first glance, the bad wines seem to have higher total sulfur dioxide, among other differences. We could use a threshold on total sulfur dioxide as a crude criterion for discriminating good wines from bad ones.\n",
        "\n",
        "Let’s get the indexes where the total sulfur dioxide column is below the midpoint we calculated earlier, like so:"
      ],
      "metadata": {
        "id": "4zXqaQWKg0HR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_sulfur_threshold = 141.83\n",
        "total_sulfur_data = data[:, 6]\n",
        "predicted_indexes = torch.lt(total_sulfur_data,\n",
        "                             total_sulfur_threshold)\n",
        "\n",
        "\n",
        "print(predicted_indexes.shape,\n",
        "      predicted_indexes.dtype,\n",
        "      predicted_indexes.sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02aT0PYigTPc",
        "outputId": "914c722a-31d8-41ce-b6a6-edb0de114c63"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4898]) torch.bool tensor(2727)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This means our threshold implies that just over half of all the wines are going to be high quality. Next, we’ll need to get the indexes of the actually good wines:"
      ],
      "metadata": {
        "id": "gCT38UH-heaT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "actual_indexes = target > 5\n",
        "\n",
        "print(actual_indexes.shape, actual_indexes.dtype, actual_indexes.sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5L5_qhuXhSVD",
        "outputId": "35fb7e01-fe58-4501-be1d-cf00be5a67c3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4898]) torch.bool tensor(3258)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since there are about 500 more actually good wines than our threshold predicted, we already have hard evidence that it’s not perfect. Now we need to see how well our predictions line up with the actual rankings. We will perform a logical “and” between our prediction indexes and the actual good indexes (remember that each is just an array of zeros and ones) and use that intersection of wines-in-agreement to determine how well we did:"
      ],
      "metadata": {
        "id": "kcncQfnEhwZz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_matches = torch.sum(actual_indexes & predicted_indexes).item()\n",
        "n_predicted = torch.sum(predicted_indexes).item()\n",
        "n_actual = torch.sum(actual_indexes).item()\n",
        "\n",
        "print(n_matches, n_matches/n_predicted, n_matches/n_actual)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HtVNsWdjhpvb",
        "outputId": "35f51476-a186-4412-b9e7-b88d605b1aa9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2018 0.74000733406674 0.6193984039287906\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We got around 2,000 wines right! Since we predicted 2,700 wines, this gives us a 74% chance that if we predict a wine to be high quality, it actually is. Unfortunately, there are 3,200 good wines, and we only identified 61% of them. Well, we got what we signed up for; that’s barely better than random! Of course, this is all very naive: we know for sure that multiple variables contribute to wine quality, and the relationships between the values of these variables and the outcome (which could be the actual score, rather than a binarized version of it) is likely more complicated than a simple\n",
        "threshold on a single value.\n",
        "\n",
        "Indeed, a simple neural network would overcome all of these limitations, as would a lot of other basic machine learning methods."
      ],
      "metadata": {
        "id": "yv-hNFuvkcTs"
      }
    }
  ]
}